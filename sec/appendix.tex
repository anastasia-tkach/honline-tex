\appendix
\section{Kalman Filter (KF)} 
\label{app:kalman}
Following the notation in~\cite{welch1995introduction}, given the measurement $z_n \in \mathbb{R}^M$, the Kalman Filter (KF) latent state $x_n \in \mathbb{R}^N$ update equations are:
% 
\begin{align}
x_n &= A x_{n - 1} +  w_{n - 1} \\
z_n &= J x_n + v_n
\end{align}
% 
where $w_n$ is a normally distributed process noise $p(w) \sim \mathcal{N}(0, Q)$, and $v_n$ is a normally distributed measurement noise $p(v) \sim \mathcal{N}(0, R)$. The matrix $A$ provides a linear estimate for state updates, while $J$ maps the state $x_n$ to the measurement $z_n$. As we are estimating a the shape of a single individual, we assume $A$ to be identity. Note that sensor noise is not normally distributed, thus our choice of $w$ can be considered an approximation \AT{not sure.. wouldn't sensor noise be accounted in \emph{measurement} noise?}:
% 
\begin{align}
x_n &= x_{n - 1} + w_{n - 1} \\
z_n &= J x_n + v_n
\end{align}
% 
In frame $n$, we provide an initial state estimate $\hat{x}_n^0$, while $\hat{x}_n$ is an improved estimate that accounts for the measurement $z_n$. We define their corresponding covariances as follows: 
% 
\begin{align}
P_n^0 &= \mathbb{E}[(x_n - \hat{x}_n^0)^T(x_n - \hat{x}_n^0)]\\
P_n   &= \mathbb{E}[(x_n - \hat{x}_n)^T(x_n - \hat{x}_n)]
\end{align}
% 
From which we can derive the time/measurement updates:
% 
\begin{gather}
% \text{\textbf{Kalman Filter (with A=I)}} \nonumber\\
\begin{aligned}
&\text{Time Update}                 &       &\text{Measurement Update} \\
\hat{x}_n^0 &= \hat{x}_{n - 1}      &       K_n &= P_n^0 J^T (J P_n^0 J^T + R)^{-1}\\
P_n^0 &= P_{n - 1} + Q              &       \hat{x}_n &= \hat{x}_n^0 + K_n (z_n - J \hat{x}_n^0) \\
&                                   &       P_n &= (I - K_n J) P_n^0 \\
\end{aligned}
\label{eq:kalman}
\end{gather}



\paragraph{Special case from \Section{combining}}
Let us consider the special case when the measurement $z_n = x_n^*$ is in the same space at the estimated state $\hat{x}_n$, thus when $J$ is the identity matrix.
% 
\begin{align*}
\hat{x}_n 
&= \hat{x}_n^0 + P_n^0  (P_n^0 + R)^{-1}(z_n - \hat{x}_n^0) \\
&= (P_n^0 + R)(P_n^0 + R)^{-1}\hat{x}_n^0 + P_n^0  (P_n^0 + R)^{-1}(z_n - \hat{x}_n^0) \\
&= R(P_n^0 + R)^{-1}\hat{x}_n^0 + P_n^0  (P_n^0 + R)^{-1}z_n \\
% 
% 
P_n &= ((P_n^0 + R) (P_n^0 + R)^{-1} - P_n^0  (P_n^0 + R)^{-1}) P_n^0\\
&= R (P_n^0 + R)^{-1} P_n^0
\end{align*}
% 
Note how these two coincide with \Equation{combining} for product of two Gaussians  with $z_n = x_n^*$, $P_n^0 = \hat{\Sigma}_{n - 1}$ and $R = \Sigma_{n}$.

\section{Extended Kalman Filter (EKF)}
The Extended Kalman Filter (EKF) estimates the latent state $x_n$ of a \emph{non-linear} system given the measurement $z_n$.
% 
\begin{align}
x_n &= \tilde{F}(x_{n - 1},  w_{n - 1}) \\
z_n &= F(x_n, v_n)
\end{align}
% 
The state $x_n$ captures parameters representing the pose and shape of our hand, and $F$ accounts for the correspondences to the measurements $z_n$, and their \emph{non-linear} characteristics with respect to hand pose and shape. In its general form, the function $\tilde{F}(\cdot)$ relates the non-linear state update, but analogously to what was done before, we assume it to be a \todo{linear} \AT{not an identity, as that is an unary operation} mapping:
% 
\begin{align}
x_n &= x_{n - 1} + w_{n - 1} \\
z_n &= F(x_n) + v_n 
\end{align}
%
By defining $F_n = F(\hat{x}_n^0)$ and ${J_n}_{[i, j]} = \partial F_{[i]} / \partial x_{[j]}(\hat{x}_n^0)$, the EKF update equations for our optimization can be written as:
% 
\begin{gather}
% \text{\textbf{Extended Kalman Filter (with linear $\tilde{F}$)}} \nonumber\\
\begin{aligned}
&\text{Time Update}                 &       &\text{Measurement Update} \\
\hat{x}_n^0 &=\hat{x}_{n-1}           &       K_n &= P_n^0 J_n^T(J_n P_n^0 J_n^T + R)^{-1}\\
P_n^0 &= P_{n-1} + Q                 &       \hat{x}_n &= \hat{x}_n^0 + K_n(z_n - F_n) \\
&                                   &       P_n &= (I - K_n J_n)P_n^0
\end{aligned}
\label{eq:kalman}
\end{gather}
% 
\AT{where is this chunk needed for? To derive the equations in \Table{extended}?}
\begin{DRAFT}
Thus, ${ \partial \tilde{F}_{[i]}}/{ \partial x_{[j]}}(\hat{x}_{n - 1}, 0) \equiv I$, ${ \partial \tilde{F}_{[i]}}/{ \partial w_{[j]}}(\hat{x}_{n - 1}, 0) \equiv I$ and ${ \partial F_{[i]}}/{ \partial v_{[j]}}(\hat{x}_n^0, 0) \equiv I$, where $I$ is an identity matrix of the corresponding size.    
\end{DRAFT}





 
