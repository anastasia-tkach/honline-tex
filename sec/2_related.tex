\section{Related Works}
Due to the vast amount of work in the area of body, face and hand tracking we refer the reader to recent works by \cite{bogo2015detailed}, \cite{cao2016real} and \cite{taylor2016joint}, \cite{tkach2016sphere} for a complete overview on respectively full-body, face and hand tracking.
Model personalization is a core ingredient in generative motion tracking \cite{pons2011model} and in this section we will focus on hand model calibration, keeping in mind that due to the large number of hand self occlusions and the amount of signal-to-noise ratio in current depth sensors the personalization of a hand model is a significantly different (and harder) problem than face or body model calibration. \ER{Any reference in mind saying why is hand calibration different and harder than face/body one? Should something talking about body and face calibration be added here?} 

\textbf{Off-line model calibration.}
\cite{albrecht2003construction} pioneered the construction of realistic (skin, bone and muscles) personalized models proposing a pipeline for the registration of a 3D mesh model to RGB data manually pre-processed by the user. Reducing the amount of manual interaction required from the user, \cite{rhee2006human} showed how skin creases and silhouette images can also be used to guide the registration of a model to color imagery. \cite{taylor2014user} introduced a more automatic pipeline, generating personalized hand models from input depth sequences where the user rotates his hand while articulating fingers. More closely related to ours is the work by \cite{tan2016fits}, demonstrating how to robustly personalize a hand model to an individual use from a set of depth measurements using trained shape basis such the one proposed by \cite{khamis2015learning}. The calibration pipeline, although robust and efficient, is not fully automated as the user needs to specify the set of frames over which the calibration optimization is performed. None of the above methods is suitable or easily adaptable to the kind of consumer-level applications that we target, being the absence of complex manual calibration or extensive pre-processing mandatory requirements for our framework.

\textbf{On-line model calibration.}
\cite{delagorce2011model} introduced a model-based approach to hand tracking from monocular RGB video sequence. Hand pose, texture and lighting are dynamically estimated through minimization of an objective function, while shape is naively determined optimizing for it over the first frame only. 
Recently \cite{makris2015model} proposed a model based approach to jointly solve the pose tracking and shape estimation from depth measurements in an online framework, solving for the cylindrical geometry of a hand through render-and-compare evaluations over a stack of frames optimized by particle swarm optimization. The pipeline they developed runs in real-time (30fps), but lacks the degree of robustness and accuracy desirable for consumer level applications.
More sophisticated approaches to information aggregation such as the one by \cite{bouaziz2013online}, where shape estimation is carried over the whole set of frames aggregated with exponential decay, allow to obtain more accurate results, while guaranteeing real-time performances. Interestingly \cite{zou2013coslam} designed a pipeline for SLAM in dynamic environments employing a time aggregation technique similar to ours. Map 3D point positions are maintained together with their associate uncertainty through a co-variance matrix, and are refined whenever a new observation is available.
\AT{face tracking: in hand tracking there are a set of \emph{default} poses that can be picked}